import os
# ---- LoglarÄ± ve uyarÄ±larÄ± en erken aÅŸamada bastÄ±r ----
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import logging
logging.getLogger('tensorflow').setLevel(logging.FATAL)
import warnings
from sklearn.exceptions import InconsistentVersionWarning
warnings.filterwarnings('ignore', category=InconsistentVersionWarning)
import sys
import re
import pickle
import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model
from tensorflow.keras.initializers import Orthogonal
from tensorflow.keras.preprocessing.sequence import pad_sequences
# ---- Rich kÃ¼tÃ¼phanesi ile geliÅŸmiÅŸ UI ----
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import track
from rich.text import Text
from rich import box
import matplotlib.pyplot as plt
import seaborn as sns

console = Console()

# ---- Dosya yollarÄ± ----
MODEL_PATH = 'CNN_balanced_model_v6.keras'
TOKENIZER_PATH = 'tokenizer_balanced_v6.pickle'
LABELENCODER_PATH = 'labelencoder_balanced_v6.pickle'

# ---- Metin temizleme ----
def clean_text(text):
    if pd.isna(text):
        return ""
    text = str(text).lower()
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'[^a-zA-ZÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄžIÄ°Ã–ÅžÃœ\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

# ---- GÃ¼ven seviyesi hesaplama ----
def calculate_confidence_metrics(probabilities):
    """Her tahmin iÃ§in detaylÄ± gÃ¼ven metrikleri hesaplar"""
    metrics = []
    for prob in probabilities:
        max_prob = np.max(prob)
        second_max = np.partition(prob, -2)[-2]
        
        # GÃ¼ven metrikleri
        confidence = max_prob
        certainty = max_prob - second_max  # En yÃ¼ksek ile ikinci en yÃ¼ksek arasÄ±ndaki fark
        entropy = -np.sum(prob * np.log(prob + 1e-8))  # Entropi (belirsizlik)
        
        # GÃ¼ven seviyesi kategorisi
        if confidence > 0.8 and certainty > 0.3:
            confidence_level = "Ã‡ok YÃ¼ksek"
            confidence_color = "bright_green"
        elif confidence > 0.6 and certainty > 0.2:
            confidence_level = "YÃ¼ksek"
            confidence_color = "green"
        elif confidence > 0.4:
            confidence_level = "Orta"
            confidence_color = "yellow"
        else:
            confidence_level = "DÃ¼ÅŸÃ¼k"
            confidence_color = "red"
        
        metrics.append({
            'confidence': confidence,
            'certainty': certainty,
            'entropy': entropy,
            'confidence_level': confidence_level,
            'confidence_color': confidence_color
        })
    
    return metrics

# ---- SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± analiz etme ----
def analyze_class_distribution(probabilities, class_names):
    """TÃ¼m sÄ±nÄ±flar iÃ§in olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ± analiz eder"""
    distribution_analysis = {}
    
    for i, class_name in enumerate(class_names):
        class_probs = probabilities[:, i]
        distribution_analysis[class_name] = {
            'ortalama': np.mean(class_probs),
            'std': np.std(class_probs),
            'min': np.min(class_probs),
            'max': np.max(class_probs),
            'medyan': np.median(class_probs)
        }
    
    return distribution_analysis

# ---- Model yÃ¼kleme ----
console.log("[bold cyan]CNN Model yÃ¼kleniyor (derlemeden)...[/]")
model = load_model(
    MODEL_PATH,
    custom_objects={'Orthogonal': Orthogonal},
    compile=False
)
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
console.log("[bold green]CNN Model yÃ¼klendi![/]")

console.log("[bold cyan]Tokenizer yÃ¼kleniyor...[/]")
with open(TOKENIZER_PATH, 'rb') as f:
    tokenizer = pickle.load(f)
console.log("[bold green]Tokenizer yÃ¼klendi![/]")

console.log("[bold cyan]LabelEncoder yÃ¼kleniyor...[/]")
with open(LABELENCODER_PATH, 'rb') as f:
    le = pickle.load(f)
console.log("[bold green]LabelEncoder yÃ¼klendi![/]")

# ---- YorumlarÄ± alma ----
if len(sys.argv) > 1:
    yorumlar = sys.argv[1:]
else:
    yorumlar = [
        "Bu Ã¼rÃ¼n gerÃ§ekten Ã§ok kÃ¶tÃ¼ydÃ¼, hiÃ§ memnun kalmadÄ±m.",
        "Harika bir alÄ±ÅŸveriÅŸti, teÅŸekkÃ¼r ederim!",
        "Kargo Ã§ok yavaÅŸ geldi ama Ã¼rÃ¼n gÃ¼zel.",
        "Bu kiÅŸi Bilgisayar MÃ¼hendisi mezunu.",
        "Orta seviyede bir Ã¼rÃ¼n, fena deÄŸil ama Ã§ok da iyi deÄŸil.",
        "Kesinlikle tavsiye etmiyorum, berbat kalite!",
        "ÃœrÃ¼n beklediÄŸimden daha iyi Ã§Ä±ktÄ±, Ã§ok memnun kaldÄ±m.",
        "Teslimat sorunsuz ve hÄ±zlÄ±ydÄ±, teÅŸekkÃ¼rler.",
        "Ambalaj Ã§ok Ã¶zensizdi, biraz daha dikkat edilmeli.",
        "ÃœrÃ¼n tasarÄ±mÄ± gÃ¼zel ama iÅŸlevselliÄŸi tatmin etmedi.",
        "Gayet gÃ¼zel bir alÄ±ÅŸveriÅŸ deneyimiydi, tekrar alabilirim.",
        "Teknik destek Ã§ok yetersizdi, sorunuma Ã§Ã¶zÃ¼m bulamadÄ±lar.",
        "Ortalama bir Ã¼rÃ¼n, ne kÃ¶tÃ¼ ne de Ã§ok iyi.",
        "Kargo paketlemesi mÃ¼kemmeldi, sorunsuz ulaÅŸtÄ±.",
        "Bu Ã¼rÃ¼n fiyatÄ±na gÃ¶re beklentimi karÅŸÄ±lamadÄ±, hayal kÄ±rÄ±klÄ±ÄŸÄ± yaÅŸadÄ±m.",
        "Bu cihazÄ±n modeli X123, Ã¶zellikleri standart.",
        "SipariÅŸ numaram 456789, teslim tarihi 10 Haziran.",
        "ÃœrÃ¼n aÃ§Ä±klamasÄ± oldukÃ§a detaylÄ± ve bilgilendiriciydi."
    ]


# ---- Ã–n iÅŸleme ve tahmin ----
console.log("[bold cyan]CNN ile tahmin iÅŸlemi baÅŸlÄ±yor...[/]")
temiz_metinler = [clean_text(y) for y in track(yorumlar, description="Metinler temizleniyor...")]
seqs = tokenizer.texts_to_sequences(temiz_metinler)
maxlen = model.input_shape[1]
padded = pad_sequences(seqs, maxlen=maxlen, padding='post', truncating='post')

# Tahmin yapma
probs = model.predict(padded, verbose=0)
predicted_indices = np.argmax(probs, axis=1)
predicted_labels = le.inverse_transform(predicted_indices)

# SÄ±nÄ±f isimlerini al
all_classes = le.classes_
confidence_metrics = calculate_confidence_metrics(probs)

# ---- Ana SonuÃ§lar Tablosu ----
main_table = Table(title="ðŸŽ¯ CNN DetaylÄ± Tahmin SonuÃ§larÄ±", expand=True, box=box.ROUNDED)
main_table.add_column("#", justify="right", style="dim", width=3)
main_table.add_column("Yorum", justify="left", width=40)
main_table.add_column("Ana Etiket", justify="center", width=12)
main_table.add_column("GÃ¼ven", justify="center", width=8)
main_table.add_column("GÃ¼ven Seviyesi", justify="center", width=12)
main_table.add_column("Belirsizlik", justify="center", width=10)

for i, (txt, lab, metrics) in enumerate(zip(yorumlar, predicted_labels, confidence_metrics), 1):
    # Ana etiket rengi
    lab_lower = lab.lower()
    if lab_lower.startswith('pos'):
        label_color = "bright_green"
    elif lab_lower.startswith('neg'):
        label_color = "bright_red"
    else:
        label_color = "bright_yellow"
    
    # KÄ±sa metin gÃ¶sterimi
    short_text = txt[:37] + "..." if len(txt) > 40 else txt
    
    main_table.add_row(
        str(i),
        short_text,
        f"[{label_color}]{lab}[/{label_color}]",
        f"{metrics['confidence']:.3f}",
        f"[{metrics['confidence_color']}]{metrics['confidence_level']}[/{metrics['confidence_color']}]",
        f"{metrics['entropy']:.3f}"
    )

console.print(main_table)

# ---- DetaylÄ± OlasÄ±lÄ±k DaÄŸÄ±lÄ±mÄ± ----
console.print("\n")
prob_table = Table(title="ðŸ“Š CNN - TÃ¼m SÄ±nÄ±flar Ä°Ã§in OlasÄ±lÄ±k DaÄŸÄ±lÄ±mÄ±", expand=True, box=box.DOUBLE_EDGE)
prob_table.add_column("Yorum #", justify="center", width=8)

# TÃ¼m sÄ±nÄ±flar iÃ§in sÃ¼tun ekle
for class_name in all_classes:
    prob_table.add_column(f"{class_name}", justify="center", width=10)

# Her yorum iÃ§in olasÄ±lÄ±k deÄŸerlerini ekle
for i, prob_row in enumerate(probs, 1):
    row_data = [str(i)]
    for j, prob_val in enumerate(prob_row):
        class_name = all_classes[j]
        # En yÃ¼ksek olasÄ±lÄ±ÄŸÄ± vurgula
        if j == predicted_indices[i-1]:
            color = "bright_green" if prob_val > 0.6 else "green"
            row_data.append(f"[{color}]{prob_val:.3f}[/{color}]")
        elif prob_val > 0.1:  # DÃ¼ÅŸÃ¼k ama dikkate deÄŸer olasÄ±lÄ±klar
            row_data.append(f"[yellow]{prob_val:.3f}[/yellow]")
        else:
            row_data.append(f"{prob_val:.3f}")
    
    prob_table.add_row(*row_data)

console.print(prob_table)

# ---- Ä°statistiksel Analiz ----
distribution_stats = analyze_class_distribution(probs, all_classes)

stats_table = Table(title="ðŸ“ˆ CNN - SÄ±nÄ±f BazlÄ± Ä°statistiksel Analiz", expand=True)
stats_table.add_column("SÄ±nÄ±f", justify="left")
stats_table.add_column("Ortalama", justify="center")
stats_table.add_column("Std. Sapma", justify="center")
stats_table.add_column("Min", justify="center")
stats_table.add_column("Max", justify="center")
stats_table.add_column("Medyan", justify="center")

for class_name, stats in distribution_stats.items():
    stats_table.add_row(
        class_name,
        f"{stats['ortalama']:.3f}",
        f"{stats['std']:.3f}",
        f"{stats['min']:.3f}",
        f"{stats['max']:.3f}",
        f"{stats['medyan']:.3f}"
    )

console.print("\n")
console.print(stats_table)

# ---- Ã–zet Panel ----
toplam_yorum = len(yorumlar)
yuksek_guven = sum(1 for m in confidence_metrics if m['confidence'] > 0.7)
dusuk_guven = sum(1 for m in confidence_metrics if m['confidence'] < 0.5)

ozet_text = f"""
ðŸ“Š CNN Model - Genel Ã–zet:
â€¢ Toplam Yorum: {toplam_yorum}
â€¢ YÃ¼ksek GÃ¼venli Tahmin: {yuksek_guven} ({yuksek_guven/toplam_yorum*100:.1f}%)
â€¢ DÃ¼ÅŸÃ¼k GÃ¼venli Tahmin: {dusuk_guven} ({dusuk_guven/toplam_yorum*100:.1f}%)
â€¢ Ortalama GÃ¼ven: {np.mean([m['confidence'] for m in confidence_metrics]):.3f}
â€¢ Tespit Edilen SÄ±nÄ±flar: {len(all_classes)}
"""

console.print(Panel(ozet_text, title="ðŸŽ¯ CNN Analiz Ã–zeti", border_style="green"))

# ---- Alternatif Tahminler ----
console.print("\n")
alt_table = Table(title="ðŸ”„ CNN - Ä°kinci ve ÃœÃ§Ã¼ncÃ¼ En YÃ¼ksek OlasÄ±lÄ±klar", expand=True)
alt_table.add_column("#", justify="center", width=3)
alt_table.add_column("1. Tahmin", justify="center", width=15)
alt_table.add_column("2. Tahmin", justify="center", width=15)
alt_table.add_column("3. Tahmin", justify="center", width=15)

for i, prob_row in enumerate(probs, 1):
    # En yÃ¼ksek 3 olasÄ±lÄ±ÄŸÄ± bul
    top3_indices = np.argsort(prob_row)[-3:][::-1]
    
    predictions_str = []
    for idx in top3_indices:
        class_name = all_classes[idx]
        prob_val = prob_row[idx]
        predictions_str.append(f"{class_name}\n({prob_val:.3f})")
    
    alt_table.add_row(str(i), *predictions_str)

console.print(alt_table)

print("\n" + "="*80)
print("âœ… CNN modeli ile detaylÄ± analiz tamamlandÄ±!")
print("ðŸ’¡ Bu analiz size CNN modelinin her tahmini iÃ§in gÃ¼ven seviyesi, alternatif tahminler ve")
print("   tÃ¼m sÄ±nÄ±flar iÃ§in olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶stermektedir.")
print("="*80)